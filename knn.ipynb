{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4077b7c-faf2-4c77-a86e-d761e96896df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit \n",
    "import random\n",
    "from sys import argv\n",
    "from math import sqrt\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7dee9-08fb-403a-97df-53815c88b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def getMeanAndStd(dataset):\n",
    "    \"\"\"\n",
    "    Accepts a 2-d array representing the dataset.\n",
    "    Returns the mean and std for each column in the dataset.\n",
    "    \"\"\"\n",
    "    meanAndStd = []\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        column = [row[i] for row in dataset]\n",
    "        mean = sum(column)/len(column)\n",
    "        sigma = 0\n",
    "        for datapoint in column:\n",
    "            sigma += abs((datapoint - mean))**2\n",
    "        \n",
    "        std = sqrt(sigma/len(column))\n",
    "        meanAndStd.append({\"mean\": mean, \"std\": std})\n",
    "\n",
    "    return meanAndStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c39cbcd-54f7-4421-9752-8cad6fb21a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(meanAndStd, dataset):\n",
    "    \"\"\"\n",
    "    Normalizes each datapoint using the function\n",
    "            f(x) = (x - mean)/std\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset[i])-1):\n",
    "            mean = meanAndStd[j][\"mean\"]\n",
    "            std = meanAndStd[j][\"std\"]\n",
    "            dataset[i][j] = (dataset[i][j] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87698804-ff3e-4dd7-9633-9018f49d3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidianDistance(row1, row2):\n",
    "    \"\"\"\n",
    "    Returns the Euclidian Distance between two vectors \n",
    "    \"\"\"\n",
    "\n",
    "    dist = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        dist += (row1[i] - row2[i])**2 \n",
    "    \n",
    "    return sqrt(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e194d7d-4053-4a2a-a0c7-c14e5c3c3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(training_data, test_row, k):\n",
    "    \"\"\"\n",
    "    Returns k nearest neighbors to a vector on\n",
    "    the basis of the shortest Euclidian Distance\n",
    "    \"\"\"\n",
    "\n",
    "    distances = list()\n",
    "    for training_row in training_data:\n",
    "        dist = euclidianDistance(training_row, test_row)\n",
    "        distances.append([training_row, dist])\n",
    "    \n",
    "    #Sort on the basis of dist\n",
    "    distances.sort(key=lambda row:row[1])\n",
    "\n",
    "    neighbors = list()\n",
    "\n",
    "    for i in range(int(k)):\n",
    "        neighbors.append(distances[i][0])\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f8b09f-3665-42fd-bfd0-fc2c371cc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictClass(training_data, test_row, k):\n",
    "    \"\"\"\n",
    "    Returns the predicted class on the basis\n",
    "    of the classes of the k nearest neighbors\n",
    "    \"\"\"\n",
    "\n",
    "    neighbors = getNeighbors(training_data, test_row, k)\n",
    "    output_vals = [row[-1] for row in neighbors]\n",
    "    \n",
    "    counts = dict()\n",
    "\n",
    "    for i in output_vals:\n",
    "        counts[i] = counts.get(i, 0) + 1\n",
    "\n",
    "    v = [value for value in counts.values()]\n",
    "\n",
    "    #Pick a class on random if ties occur\n",
    "    prediction = choice([key for key in counts if counts[key] == max(v)])\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d007020-3f48-460c-9a7d-c6868a8180b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCounts(training_data, test_row, k):\n",
    "    \"\"\"\n",
    "    Returns the count of each class as a dictionary\n",
    "    to calculate accuracy\n",
    "    \"\"\"\n",
    "    neighbors = getNeighbors(training_data, test_row, k)\n",
    "    output_vals = [row[-1] for row in neighbors]\n",
    "\n",
    "    counts = dict()\n",
    "\n",
    "    for i in output_vals:\n",
    "        counts[i] = counts.get(i, 0) + 1\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e34149-1e95-4f8b-b650-084d6b1ad044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy when k= 1 : 97.42710120068611 %\n",
      "classification accuracy when k= 2 : 97.5557461406518 %\n",
      "classification accuracy when k= 3 : 97.51286449399659 %\n"
     ]
    }
   ],
   "source": [
    "#@jit(nopython = True)\n",
    "i = range(1, 10)\n",
    "for k in i:\n",
    "    \n",
    "    training_file = open(\"pendigits_training.txt\", 'r')\n",
    "    test_file = open(\"pendigits_test.txt\", 'r')\n",
    "\n",
    "    training_dataset = []\n",
    "    for line in training_file:\n",
    "        training_dataset.append([int(datapoint) for datapoint in line.split()])\n",
    "\n",
    "    test_dataset = []\n",
    "    for line in test_file:\n",
    "        test_dataset.append([int(datapoint) for datapoint in line.split()])\n",
    "    \n",
    "    meanAndStd = getMeanAndStd(training_dataset)\n",
    "\n",
    "    normalizeData(meanAndStd, training_dataset)\n",
    "    normalizeData(meanAndStd, test_dataset)\n",
    "\n",
    "    classification_accuracy = 0\n",
    "\n",
    "    for i in range(len(test_dataset)):\n",
    "        row = test_dataset[i]\n",
    "        predicted_class = predictClass(training_dataset, row, k)\n",
    "        true_class = row[-1]\n",
    "        accuracy = 0\n",
    "\n",
    "        counts = getCounts(training_dataset, row, k)\n",
    "        v = [value for value in counts.values()]\n",
    "    \n",
    "        if(v.count(max(v)) == 1 and (predicted_class==true_class)):\n",
    "            accuracy = 1\n",
    "        elif(v.count(max(v)) > 1 and counts[predicted_class] == max(v)):\n",
    "            accuracy = 1/v.count(max(v))\n",
    "            \n",
    "        #print(\"ID={0:5d}, predicted={1:3d}, true={2:3d}, accuracy={3:5.2f}\\n\".format(i, predicted_class, true_class, accuracy))\n",
    "        classification_accuracy += accuracy\n",
    "        \n",
    "    classification_accuracy = classification_accuracy/len(test_dataset)\n",
    "\n",
    "    print(\"classification accuracy when k=\",k,\":\",classification_accuracy*100,\"%\")\n",
    "\n",
    "    training_file.close()\n",
    "    test_file.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
